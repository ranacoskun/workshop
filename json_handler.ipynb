{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# JSON Retriever  \n",
        "Create a chain to retrieve information from json by making a request to a web page"
      ],
      "metadata": {
        "id": "E6Q22tdhZobh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bQUwP4hdWiZM"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import requests\n",
        "\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_core.callbacks import CallbackManager, StreamingStdOutCallbackHandler\n",
        "from langchain_community.document_loaders import JSONLoader\n",
        "from langchain_community.embeddings.ollama import OllamaEmbeddings\n",
        "from langchain_community.llms import Ollama"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a json saver to get response and save as json\n",
        "def save_response_as_json(url, filename):\n",
        "    response = requests.get(url)\n",
        "    data = response.json()\n",
        "    with open(filename, 'w') as f:\n",
        "        json.dump(data, f)"
      ],
      "metadata": {
        "id": "B_FcdEw1W3uD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://jsonplaceholder.typicode.com/posts/1\"\n",
        "path = \"response.json\""
      ],
      "metadata": {
        "id": "jB7uIYJhWzz1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_response_as_json(url, path)"
      ],
      "metadata": {
        "id": "SvCHPq2sW6oL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create json loader without any specific schema\n",
        "loader = JSONLoader(\n",
        "    file_path=path,\n",
        "    jq_schema='.',\n",
        "    text_content=False)"
      ],
      "metadata": {
        "id": "gcx9-jOSW9En"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load json\n",
        "data = loader.load()"
      ],
      "metadata": {
        "id": "f8kG30uGYPpn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create vectorstore from data\n",
        "embeddings = OllamaEmbeddings(model=\"llama3\")\n",
        "vectorStore = Chroma.from_documents(data, embeddings)"
      ],
      "metadata": {
        "id": "VHNRkw9cf3PR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create retriever to get related information\n",
        "retriever = vectorStore.as_retriever(search_kwargs={\"k\": 1}) # the retriever uses similarity_search, which has a default value of  n_results k=4"
      ],
      "metadata": {
        "id": "i713_SYqXu9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LLM\n",
        "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
        "ollama_llm = Ollama(\n",
        "    model = 'llama3',\n",
        "    verbose= False,\n",
        "    callback_manager=callback_manager\n",
        "    )"
      ],
      "metadata": {
        "id": "vytfBpS8Xz0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create propt template to feed the llm\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"history\", \"context\", \"question\"],\n",
        "    template= \"\"\"You're an asistant that is talking to a customer. You are retrieving responses in json format as results of requests.\n",
        "    Answer only the questions about the documents and contexts you have. If you don't know the answer,\n",
        "    say that you don't know. Keep your replies short. Don't hallucinate, give only a simple answer.\n",
        "\n",
        "    Contexts:{context}\n",
        "    History: {history}\n",
        "\n",
        "    User: {question}\n",
        "    Chatbot:\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "eUZdVomcX1rv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create memory agent to save the chat history\n",
        "memory = ConversationBufferMemory(\n",
        "       memory_key=\"history\",\n",
        "       return_messages=True,\n",
        "       input_key=\"question\",\n",
        "   )"
      ],
      "metadata": {
        "id": "1JbakCb7X3x0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    user_input = input(\"You:\")\n",
        "    docs = retriever.invoke(user_input)\n",
        "    chain = prompt | ollama_llm\n",
        "    if user_input.lower() in [\"bye\", \"exit\"]:\n",
        "        break\n",
        "    chain.invoke({\n",
        "        \"question\": user_input,\n",
        "        \"history\": memory,\n",
        "        \"context\": docs  # \"contexts\": \"\\n---\\n\".join([d.page_content for d in docs])\n",
        "        }\n",
        "    )\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "ENkkGZf6X57X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}